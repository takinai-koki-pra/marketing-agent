#!/usr/bin/env python3
"""
ãƒšãƒ«ã‚½ãƒŠãƒ™ãƒ¼ã‚¹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ãƒšãƒ«ã‚½ãƒŠåˆ†æãƒ„ãƒ¼ãƒ«

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒšãƒ«ã‚½ãƒŠã‚’åˆ†æãƒ»ç”Ÿæˆã—ã¾ã™ã€‚
- ãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»è§£æ
- ãƒšãƒ«ã‚½ãƒŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ
- çµ±è¨ˆå‡¦ç†ãƒ»ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
- JSONå½¢å¼ã§ã®çµæœå‡ºåŠ›

ä½¿ç”¨æ–¹æ³•:
    python persona-analyzer.py --input research-data.csv       # CSVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ†æ
    python persona-analyzer.py --project 20250703             # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨åˆ†æ
    python persona-analyzer.py --sample                       # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§åˆ†æ
"""

import os
import sys
import argparse
import datetime
import json
import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Any
import matplotlib.pyplot as plt
import seaborn as sns

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Yu Gothic', 'Meiryo', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('persona-analyzer.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
OUTPUTS_DIR = PROJECT_ROOT / "outputs"

class PersonaAnalyzer:
    """ãƒšãƒ«ã‚½ãƒŠåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_name: str = None):
        self.project_name = project_name or datetime.datetime.now().strftime('%Y%m%d')
        self.project_dir = OUTPUTS_DIR / self.project_name
        self.data = None
        self.personas = []
        self.analysis_results = {}
    
    def load_sample_data(self) -> pd.DataFrame:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        logger.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        
        np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        n_samples = 1000
        data = {
            'age': np.random.normal(35, 12, n_samples).astype(int),
            'gender': np.random.choice(['ç”·æ€§', 'å¥³æ€§'], n_samples, p=[0.48, 0.52]),
            'income': np.random.normal(450, 150, n_samples).astype(int),  # ä¸‡å††
            'occupation': np.random.choice([
                'ä¼šç¤¾å“¡', 'å…¬å‹™å“¡', 'è‡ªå–¶æ¥­', 'å°‚æ¥­ä¸»å©¦ãƒ»ä¸»å¤«', 
                'å­¦ç”Ÿ', 'ãƒ‘ãƒ¼ãƒˆãƒ»ã‚¢ãƒ«ãƒã‚¤ãƒˆ', 'é€€è·è€…'
            ], n_samples, p=[0.4, 0.1, 0.15, 0.1, 0.05, 0.15, 0.05]),
            'region': np.random.choice([
                'é–¢æ±', 'é–¢è¥¿', 'ä¸­éƒ¨', 'ä¹å·', 'æ±åŒ—', 'ä¸­å›½ãƒ»å››å›½', 'åŒ—æµ·é“ãƒ»æ²–ç¸„'
            ], n_samples, p=[0.35, 0.2, 0.15, 0.1, 0.08, 0.07, 0.05]),
            'lifestyle': np.random.choice([
                'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–', 'å®¶åº­é‡è¦–', 'ã‚­ãƒ£ãƒªã‚¢é‡è¦–', 'è¶£å‘³é‡è¦–', 'ãƒãƒ©ãƒ³ã‚¹é‡è¦–'
            ], n_samples, p=[0.2, 0.25, 0.2, 0.15, 0.2]),
            'tech_savvy': np.random.choice([
                'é«˜ã„', 'æ™®é€š', 'ä½ã„'
            ], n_samples, p=[0.3, 0.5, 0.2]),
            'spending_pattern': np.random.choice([
                'ä¾¡æ ¼é‡è¦–', 'å“è³ªé‡è¦–', 'ãƒ–ãƒ©ãƒ³ãƒ‰é‡è¦–', 'åˆ©ä¾¿æ€§é‡è¦–'
            ], n_samples, p=[0.3, 0.35, 0.15, 0.2])
        }
        
        # å¹´é½¢ã«ã‚ˆã‚‹èª¿æ•´
        df = pd.DataFrame(data)
        df.loc[df['age'] < 25, 'income'] = df.loc[df['age'] < 25, 'income'] * 0.6
        df.loc[df['age'] > 60, 'income'] = df.loc[df['age'] > 60, 'income'] * 0.8
        df['income'] = df['income'].clip(lower=150, upper=1000)  # 150-1000ä¸‡å††ã®ç¯„å›²
        
        return df
    
    def load_csv_data(self, file_path: Path) -> pd.DataFrame:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        logger.info(f"CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {file_path}")
        
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
            return df
        except Exception as e:
            logger.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def analyze_demographics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """äººå£çµ±è¨ˆå­¦çš„åˆ†æ"""
        logger.info("äººå£çµ±è¨ˆå­¦çš„åˆ†æã‚’å®Ÿè¡Œä¸­...")
        
        demographics = {
            'age_stats': {
                'mean': float(df['age'].mean()),
                'median': float(df['age'].median()),
                'std': float(df['age'].std()),
                'min': int(df['age'].min()),
                'max': int(df['age'].max())
            },
            'gender_distribution': df['gender'].value_counts().to_dict(),
            'income_stats': {
                'mean': float(df['income'].mean()),
                'median': float(df['income'].median()),
                'std': float(df['income'].std())
            },
            'occupation_distribution': df['occupation'].value_counts().to_dict(),
            'region_distribution': df['region'].value_counts().to_dict(),
            'lifestyle_distribution': df['lifestyle'].value_counts().to_dict()
        }
        
        return demographics
    
    def segment_personas(self, df: pd.DataFrame, n_personas: int = 3) -> List[Dict[str, Any]]:
        """ãƒšãƒ«ã‚½ãƒŠã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        logger.info(f"{n_personas}å€‹ã®ãƒšãƒ«ã‚½ãƒŠã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆä¸­...")
        
        from sklearn.cluster import KMeans
        from sklearn.preprocessing import LabelEncoder
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        df_encoded = df.copy()
        encoders = {}
        
        categorical_columns = ['gender', 'occupation', 'region', 'lifestyle', 'tech_savvy', 'spending_pattern']
        for col in categorical_columns:
            if col in df_encoded.columns:
                le = LabelEncoder()
                df_encoded[col + '_encoded'] = le.fit_transform(df_encoded[col])
                encoders[col] = le
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ç”¨ã®ç‰¹å¾´é‡é¸æŠ
        feature_columns = ['age', 'income'] + [col + '_encoded' for col in categorical_columns if col in df.columns]
        X = df_encoded[feature_columns]
        
        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        kmeans = KMeans(n_clusters=n_personas, random_state=42, n_init=10)
        df_encoded['cluster'] = kmeans.fit_predict(X)
        
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ä»£è¡¨çš„ãªãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ
        personas = []
        for i in range(n_personas):
            cluster_data = df[df_encoded['cluster'] == i]
            
            persona = {
                'id': i + 1,
                'name': f'ãƒšãƒ«ã‚½ãƒŠ{i + 1}',
                'size': len(cluster_data),
                'percentage': round(len(cluster_data) / len(df) * 100, 1),
                'characteristics': {
                    'age_range': f"{int(cluster_data['age'].quantile(0.25))}-{int(cluster_data['age'].quantile(0.75))}æ­³",
                    'typical_age': int(cluster_data['age'].median()),
                    'gender_ratio': cluster_data['gender'].value_counts(normalize=True).to_dict(),
                    'income_range': f"{int(cluster_data['income'].quantile(0.25))}-{int(cluster_data['income'].quantile(0.75))}ä¸‡å††",
                    'typical_income': int(cluster_data['income'].median()),
                    'top_occupation': cluster_data['occupation'].mode().iloc[0],
                    'top_region': cluster_data['region'].mode().iloc[0],
                    'top_lifestyle': cluster_data['lifestyle'].mode().iloc[0],
                    'tech_savvy_level': cluster_data['tech_savvy'].mode().iloc[0],
                    'spending_preference': cluster_data['spending_pattern'].mode().iloc[0]
                }
            }
            
            personas.append(persona)
        
        return personas
    
    def generate_persona_descriptions(self, personas: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ãƒšãƒ«ã‚½ãƒŠã®è©³ç´°èª¬æ˜ã‚’ç”Ÿæˆ"""
        logger.info("ãƒšãƒ«ã‚½ãƒŠã®è©³ç´°èª¬æ˜ã‚’ç”Ÿæˆä¸­...")
        
        # ãƒšãƒ«ã‚½ãƒŠåã®ãƒãƒƒãƒ”ãƒ³ã‚°
        persona_names = [
            "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ç”°ä¸­", "ãƒãƒ©ãƒ³ã‚¹ä½è—¤", "å“è³ªå¿—å‘ã®å±±ç”°",
            "ã‚³ã‚¹ãƒˆé‡è¦–ã®éˆ´æœ¨", "ãƒˆãƒ¬ãƒ³ãƒ‰æ•æ„Ÿãªé«˜æ©‹"
        ]
        
        # ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«èª¬æ˜ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        lifestyle_descriptions = {
            'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–': 'ç©æ¥µçš„ã«æ–°ã—ã„ã“ã¨ã«æŒ‘æˆ¦ã—ã€å¤–å‡ºã‚„ã‚¤ãƒ™ãƒ³ãƒˆå‚åŠ ã‚’å¥½ã‚€',
            'å®¶åº­é‡è¦–': 'å®¶æ—ã¨ã®æ™‚é–“ã‚’å¤§åˆ‡ã«ã—ã€å®‰å®šã—ãŸæ—¥å¸¸ã‚’æ±‚ã‚ã‚‹',
            'ã‚­ãƒ£ãƒªã‚¢é‡è¦–': 'ä»•äº‹ã§ã®æˆåŠŸã‚’é‡è¦–ã—ã€è‡ªå·±æŠ•è³‡ã«ç©æ¥µçš„',
            'è¶£å‘³é‡è¦–': 'å€‹äººã®è¶£å‘³ã‚„èˆˆå‘³ã‚’å„ªå…ˆã—ã€è‡ªåˆ†ã®æ™‚é–“ã‚’å¤§åˆ‡ã«ã™ã‚‹',
            'ãƒãƒ©ãƒ³ã‚¹é‡è¦–': 'ä»•äº‹ã¨ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã®ãƒãƒ©ãƒ³ã‚¹ã‚’é‡è¦–ã™ã‚‹'
        }
        
        for i, persona in enumerate(personas):
            characteristics = persona['characteristics']
            
            # ã‚ˆã‚Šè©³ç´°ãªèª¬æ˜ã‚’è¿½åŠ 
            persona['detailed_profile'] = {
                'name': persona_names[i] if i < len(persona_names) else f"ãƒšãƒ«ã‚½ãƒŠ{persona['id']}",
                'summary': f"{characteristics['typical_age']}æ­³ã®{characteristics['top_occupation']}ã€‚{characteristics['top_region']}åœ¨ä½ã€‚",
                'lifestyle_description': lifestyle_descriptions.get(
                    characteristics['top_lifestyle'], 
                    f"{characteristics['top_lifestyle']}ãªç”Ÿæ´»ã‚¹ã‚¿ã‚¤ãƒ«"
                ),
                'purchase_behavior': f"{characteristics['spending_preference']}ã§å•†å“ã‚’é¸æŠã€‚ITãƒªãƒ†ãƒ©ã‚·ãƒ¼ã¯{characteristics['tech_savvy_level']}ã€‚",
                'communication_preference': self._get_communication_preference(characteristics),
                'pain_points': self._generate_pain_points(characteristics),
                'motivations': self._generate_motivations(characteristics)
            }
        
        return personas
    
    def _get_communication_preference(self, characteristics: Dict) -> str:
        """ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å—œå¥½ã‚’ç”Ÿæˆ"""
        tech_level = characteristics['tech_savvy_level']
        age = characteristics['typical_age']
        
        if tech_level == 'é«˜ã„':
            return "SNSã€ã‚¢ãƒ—ãƒªã€Webã‚µã‚¤ãƒˆã§ã®æƒ…å ±åé›†ã‚’å¥½ã‚€"
        elif age < 30:
            return "SNSã‚„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’æ´»ç”¨"
        elif age > 50:
            return "ãƒ†ãƒ¬ãƒ“ã€æ–°èã€å£ã‚³ãƒŸã‚’é‡è¦–"
        else:
            return "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã®æƒ…å ±ã‚’ãƒãƒ©ãƒ³ã‚¹è‰¯ãæ´»ç”¨"
    
    def _generate_pain_points(self, characteristics: Dict) -> List[str]:
        """ãƒšã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        pain_points = []
        
        if characteristics['spending_preference'] == 'ä¾¡æ ¼é‡è¦–':
            pain_points.append("ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä½ã„å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹")
        elif characteristics['spending_preference'] == 'å“è³ªé‡è¦–':
            pain_points.append("å“è³ªã®ä¸å®‰å®šã•ã‚„ä¿¡é ¼æ€§ã®æ¬ å¦‚")
        
        if characteristics['tech_savvy_level'] == 'ä½ã„':
            pain_points.append("è¤‡é›‘ãªæ“ä½œã‚„è¨­å®šãŒå¿…è¦ãªã‚µãƒ¼ãƒ“ã‚¹")
        
        if characteristics['top_lifestyle'] == 'å®¶åº­é‡è¦–':
            pain_points.append("å®¶æ—ã¨ã®æ™‚é–“ã‚’å¥ªã‚ã‚Œã‚‹ã“ã¨")
        
        return pain_points or ["æ™‚é–“ã®ç„¡é§„", "æœŸå¾…å€¤ã¨ã®ã‚®ãƒ£ãƒƒãƒ—"]
    
    def _generate_motivations(self, characteristics: Dict) -> List[str]:
        """ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        motivations = []
        
        if characteristics['top_lifestyle'] == 'ã‚­ãƒ£ãƒªã‚¢é‡è¦–':
            motivations.append("ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ãƒ»ã‚­ãƒ£ãƒªã‚¢å‘ä¸Š")
        elif characteristics['top_lifestyle'] == 'å®¶åº­é‡è¦–':
            motivations.append("å®¶æ—ã®å¹¸ã›ãƒ»å®‰å¿ƒ")
        elif characteristics['top_lifestyle'] == 'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–':
            motivations.append("æ–°ã—ã„ä½“é¨“ãƒ»æŒ‘æˆ¦")
        
        if characteristics['spending_preference'] == 'ãƒ–ãƒ©ãƒ³ãƒ‰é‡è¦–':
            motivations.append("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»è‡ªå·±è¡¨ç¾")
        
        return motivations or ["ç”Ÿæ´»ã®è³ªå‘ä¸Š", "æ™‚é–“ã®æœ‰åŠ¹æ´»ç”¨"]
    
    def create_visualizations(self, df: pd.DataFrame, personas: List[Dict[str, Any]]):
        """ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚’ä½œæˆ"""
        logger.info("ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        vis_dir = self.project_dir / "visualizations"
        vis_dir.mkdir(exist_ok=True)
        
        # 1. å¹´é½¢åˆ†å¸ƒ
        plt.figure(figsize=(10, 6))
        plt.hist(df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('å¹´é½¢åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('å¹´é½¢')
        plt.ylabel('äººæ•°')
        plt.grid(True, alpha=0.3)
        plt.savefig(vis_dir / 'age_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. åå…¥åˆ†å¸ƒ
        plt.figure(figsize=(10, 6))
        plt.hist(df['income'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        plt.title('åå…¥åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('å¹´åï¼ˆä¸‡å††ï¼‰')
        plt.ylabel('äººæ•°')
        plt.grid(True, alpha=0.3)
        plt.savefig(vis_dir / 'income_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. ãƒšãƒ«ã‚½ãƒŠã‚µã‚¤ã‚ºæ¯”è¼ƒ
        persona_names = [p['detailed_profile']['name'] for p in personas]
        persona_sizes = [p['size'] for p in personas]
        
        plt.figure(figsize=(10, 6))
        plt.pie(persona_sizes, labels=persona_names, autopct='%1.1f%%', startangle=90)
        plt.title('ãƒšãƒ«ã‚½ãƒŠåˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.savefig(vis_dir / 'persona_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {vis_dir}")
    
    def save_results(self, df: pd.DataFrame, personas: List[Dict[str, Any]], demographics: Dict[str, Any]):
        """çµæœã‚’ä¿å­˜"""
        logger.info("åˆ†æçµæœã‚’ä¿å­˜ä¸­...")
        
        # çµæœãƒ‡ãƒ¼ã‚¿ä½œæˆ
        results = {
            'project_info': {
                'project_name': self.project_name,
                'analysis_date': datetime.datetime.now().isoformat(),
                'data_size': len(df),
                'persona_count': len(personas)
            },
            'demographics': demographics,
            'personas': personas,
            'metadata': {
                'version': '1.0',
                'analyzer': 'persona-analyzer.py'
            }
        }
        
        # JSONä¿å­˜
        output_file = self.project_dir / f"persona-analysis-{self.project_name}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"åˆ†æçµæœã‚’ä¿å­˜: {output_file}")
        return results
    
    def run_analysis(self, data_source: str = 'sample', n_personas: int = 3):
        """åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"ãƒšãƒ«ã‚½ãƒŠåˆ†æé–‹å§‹: {self.project_name}")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if data_source == 'sample':
            df = self.load_sample_data()
        else:
            df = self.load_csv_data(Path(data_source))
        
        # åŸºæœ¬çµ±è¨ˆåˆ†æ
        demographics = self.analyze_demographics(df)
        
        # ãƒšãƒ«ã‚½ãƒŠã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        personas = self.segment_personas(df, n_personas)
        
        # è©³ç´°èª¬æ˜ç”Ÿæˆ
        personas = self.generate_persona_descriptions(personas)
        
        # å¯è¦–åŒ–ä½œæˆ
        self.create_visualizations(df, personas)
        
        # çµæœä¿å­˜
        results = self.save_results(df, personas, demographics)
        
        logger.info(f"ãƒšãƒ«ã‚½ãƒŠåˆ†æå®Œäº†: {self.project_name}")
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='ãƒšãƒ«ã‚½ãƒŠãƒ™ãƒ¼ã‚¹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ãƒšãƒ«ã‚½ãƒŠåˆ†æãƒ„ãƒ¼ãƒ«'
    )
    
    parser.add_argument(
        '--input',
        type=str,
        help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    
    parser.add_argument(
        '--project',
        type=str,
        help='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå (YYYYMMDDå½¢å¼)'
    )
    
    parser.add_argument(
        '--sample',
        action='store_true',
        help='ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§åˆ†æ'
    )
    
    parser.add_argument(
        '--personas',
        type=int,
        default=3,
        help='ç”Ÿæˆã™ã‚‹ãƒšãƒ«ã‚½ãƒŠæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3)'
    )
    
    args = parser.parse_args()
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåæ±ºå®š
    project_name = args.project or datetime.datetime.now().strftime('%Y%m%d')
    
    # åˆ†æå™¨åˆæœŸåŒ–
    analyzer = PersonaAnalyzer(project_name)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    analyzer.project_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ±ºå®š
        if args.sample or (not args.input):
            data_source = 'sample'
        else:
            data_source = args.input
        
        # åˆ†æå®Ÿè¡Œ
        results = analyzer.run_analysis(data_source, args.personas)
        
        print(f"\nâœ… ãƒšãƒ«ã‚½ãƒŠåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_name}")
        print(f"ğŸ‘¥ ç”Ÿæˆãƒšãƒ«ã‚½ãƒŠæ•°: {len(results['personas'])}")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {results['project_info']['data_size']}ä»¶")
        print(f"ğŸ“‚ çµæœä¿å­˜å…ˆ: {analyzer.project_dir}")
        
        # ãƒšãƒ«ã‚½ãƒŠä¸€è¦§è¡¨ç¤º
        print(f"\nğŸ¯ ç”Ÿæˆã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠ:")
        for persona in results['personas']:
            profile = persona['detailed_profile']
            print(f"  - {profile['name']}: {profile['summary']}")
        
    except Exception as e:
        logger.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 